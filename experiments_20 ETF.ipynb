{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\DLinear\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 找不到指定的程序。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "d:\\Anaconda3\\envs\\DLinear\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n",
      "d:\\Anaconda3\\envs\\DLinear\\lib\\site-packages\\torchaudio\\backend\\utils.py:89: UserWarning: No audio backend is available.\n",
      "  warnings.warn('No audio backend is available.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "from datetime import datetime, timedelta\n",
    "rdseed = 123\n",
    "def set_all_seeds(seed):\n",
    "  random.seed(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "set_all_seeds(rdseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLinear模型\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "class DLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Decomposition-Linear\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, pred_len, kernel_size):\n",
    "        super(DLinear, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        # Decompsition Kernel Size\n",
    "        self.decompsition = series_decomp(kernel_size)\n",
    "\n",
    "        self.Linear_Seasonal = nn.Linear(self.seq_len,self.pred_len)\n",
    "        self.Linear_Trend = nn.Linear(self.seq_len,self.pred_len)\n",
    "        \n",
    "        # Use this two lines if you want to visualize the weights\n",
    "        # self.Linear_Seasonal.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "        # self.Linear_Trend.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Input length, Channel]\n",
    "        seasonal_init, trend_init = self.decompsition(x)\n",
    "        seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    " \n",
    "        seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "\n",
    "        trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "        x = seasonal_output + trend_output\n",
    "        return x.permute(0,2,1) # to [Batch, Output length, Channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, df, seq_len, pred_len):\n",
    "        self.df = df\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # input\n",
    "        input_begin = index\n",
    "        input_end = input_begin + self.seq_len\n",
    "\n",
    "        # label\n",
    "        label_begin = input_end\n",
    "        label_end = label_begin + self.pred_len\n",
    "\n",
    "        seq_x = self.df[input_begin:input_end]\n",
    "        seq_y = self.df[label_begin:label_end]\n",
    "\n",
    "        return seq_x, seq_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "def shift_date_24(start_date, days_to_shift):\n",
    "    # 将字符串格式日期转换为 datetime 对象\n",
    "    date_obj = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    \n",
    "    # 向后推移指定天数\n",
    "    shifted_date = date_obj + timedelta(days=days_to_shift)\n",
    "    \n",
    "    # 将结果转换为字符串格式并返回\n",
    "    shifted_date_str = shifted_date.strftime('%Y-%m-%d')\n",
    "    return shifted_date_str\n",
    "# 重新初始化模型的权重\n",
    "def reset_weights(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['IAI', 'IVV', 'ESGU', 'PICK', 'QUAL', 'SLV', 'IWB', 'HEWJ', 'RING', 'IAU', 'IYY', 'EWT', 'ITOT', 'IWV', 'IAK', 'ILCB', 'DIVB', 'ICVT', 'DGRO', 'IFRA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.14it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 245.21it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 223.10it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 232.75it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 233.67it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 223.91it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 210.71it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 210.09it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 147.24it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 197.64it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 186.71it/s]\n",
      "C:\\Users\\123\\AppData\\Local\\Temp\\ipykernel_14592\\2780280762.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  REAL['pred'] = RES.values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAI:          date       Open       High        Low      Close  Adj Close  Volume  \\\n",
      "317 2021-01-04  80.629997  80.629997  78.290001  79.160004  74.832153  110400   \n",
      "318 2021-01-05  79.099998  80.029999  78.239998  79.669998  75.314270   28500   \n",
      "319 2021-01-06  80.699997  84.580002  80.699997  83.959999  79.369713  227400   \n",
      "320 2021-01-07  84.949997  86.080002  84.949997  85.610001  80.929512   31700   \n",
      "321 2021-01-08  85.739998  85.739998  84.639999  85.739998  81.052399   27500   \n",
      "\n",
      "       Return  \n",
      "317  1.282566  \n",
      "318  1.290829  \n",
      "319  1.360337  \n",
      "320  1.387071  \n",
      "321  1.389177  \n",
      "IVV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 201.89it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 179.31it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 182.36it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 232.49it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 238.01it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 209.51it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 194.55it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 200.71it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 207.99it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 195.77it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for ticker in tickers: \n",
    "    start_date = '2019-10-01'\n",
    "    end_date = '2021-01-01'\n",
    "    print(ticker)\n",
    "    RES = pd.DataFrame()   \n",
    "    for i in range(11):    \n",
    "        # history : 2019-10-01 ~ 2022-01-01 的数据\n",
    "        history = pd.read_csv(f'data\\{ticker}.csv')\n",
    "        history['date'] = pd.to_datetime(history['date'])\n",
    "\n",
    "        # data : Warming Up 期间的数据\n",
    "        data = history[(history['date'] >= start_date) \n",
    "                    & (history['date'] <= end_date)]\n",
    "        df = data[[\"Return\"]]\n",
    "        #df.plot(figsize=(15,5), title=\"Closing Price of Asset\")\n",
    "        df = df.reset_index(drop=True)\n",
    "        #df.plot(figsize=(15,5), title = 'Daily percentage change (Daily Return)')\n",
    "        df_norm = df.to_numpy()\n",
    "        num_epoch = 200\n",
    "        config = dict(\n",
    "            batch_size= 64,\n",
    "            kernel_size= 21,\n",
    "            learning_rate= 0.0001,\n",
    "            seq_len= 96,\n",
    "            pred_len= 24,\n",
    "        )\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        data_set = Dataset_Custom(\n",
    "                df=df_norm,\n",
    "                seq_len=config['seq_len'],\n",
    "                pred_len=config['pred_len']\n",
    "                )\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "                data_set,\n",
    "                batch_size=config['batch_size'],\n",
    "                shuffle=True,\n",
    "                drop_last=False)\n",
    "\n",
    "        model = DLinear(seq_len=config['seq_len'],\n",
    "                        pred_len=config['pred_len'],\n",
    "                        kernel_size=config['kernel_size']\n",
    "                        ).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "        criterion = nn.L1Loss().to(device)\n",
    "\n",
    "        train_loss_ep = []\n",
    "        for epoch in tqdm(range(num_epoch)):\n",
    "            train_loss = []\n",
    "\n",
    "            model.train()\n",
    "            for i, (batch_x, batch_y) in enumerate(data_loader):\n",
    "                \n",
    "                batch_x = batch_x.float().to(device)\n",
    "                batch_y = batch_y.float().to(device)\n",
    "\n",
    "                outputs = model(batch_x)\n",
    "\n",
    "\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #log\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "            train_loss_ep.append(np.average(train_loss))\n",
    "\n",
    "            #print(f\"Epoch: {epoch+1}/{num_epoch}, Training Loss: {np.average(train_loss)}\")\n",
    "        #pd.DataFrame(train_loss_ep).plot()\n",
    "        r = df_norm[-config['seq_len']:,:]\n",
    "        x = torch.tensor(r[-config['seq_len']:,:]).unsqueeze(0)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(x.float().to(device))\n",
    "        r = np.append(r, output.squeeze(0).to(\"cpu\").detach().numpy(), axis=0)\n",
    "        res_df = pd.DataFrame(r[-24:])\n",
    "        res_df.columns = [\"ret_pred\"]\n",
    "        #res_df.plot(figsize=(15,5))\n",
    "        if RES.empty:\n",
    "            RES = res_df\n",
    "        else :\n",
    "            RES = pd.concat([RES,res_df],axis = 0, ignore_index = True)\n",
    "        start_date = shift_date_24(start_date, 24)\n",
    "        end_date = shift_date_24(end_date, 24)\n",
    "        reset_weights(model)\n",
    "    \n",
    "    \n",
    "    REAL = history[(history['date'] >= '2021-01-04') \n",
    "                & (history['date'] <= '2022-01-19')]\n",
    "    print(f'{ticker}:{REAL.head()}')\n",
    "    REAL['pred'] = RES.values\n",
    "\n",
    "    # 假设 pred 和 real 是你的两个时间序列数据\n",
    "\n",
    "    # 创建一个新的图形\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    # 绘制 pred 数据\n",
    "    plt.plot(REAL['pred'], label='Predicted', color='blue')\n",
    "\n",
    "    # 绘制 real 数据\n",
    "    plt.plot(REAL['Return'], label='Real', color='red')\n",
    "\n",
    "    # 添加标题和标签\n",
    "    plt.title(f'{ticker} Predicted vs Real')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.ylim(0.8, 2.0)\n",
    "    # 添加图例\n",
    "    plt.legend()\n",
    "\n",
    "    # 显示图形\n",
    "    plt.savefig(f'image\\{rdseed}_{ticker}png', dpi=300)\n",
    "\n",
    "    REAL.to_csv(f'res\\{rdseed}_{ticker}pred.csv', index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
